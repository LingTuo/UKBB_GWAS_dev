{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Working directory: change accordingly\n",
    "parameter: cwd = path\n",
    "# Genotype file in plink binary format\n",
    "parameter: bfile = path\n",
    "# Path to bgen files\n",
    "parameter: bgenFile = paths\n",
    "# Path to sample file\n",
    "parameter: sampleFile = path\n",
    "# Path to summary stats file\n",
    "parameter: sumstatsFile = path\n",
    "# Path to samples of unrelated individuals\n",
    "parameter: unrelated_samples = path\n",
    "# Number of samples to use to compute LD\n",
    "parameter: ld_sample_size = 1000\n",
    "# Clumping parameteres\n",
    "parameter: clump_field = str\n",
    "parameter: clump_annotate = str\n",
    "parameter: clump_p1 = 5e-08\n",
    "parameter: clump_p2 = 1\n",
    "# r2 = 0.04 => r = 0.2\n",
    "parameter: clump_r2 = 0.04\n",
    "parameter: clump_kb = 2000\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Output the bgen file with 8bit formatting\n",
    "#parameter: bgen_bits=16\n",
    "# Specific number of threads to use\n",
    "parameter: numThreads = int\n",
    "# Load specific modules for each step\n",
    "parameter: qctool_module = '''\n",
    "module load QCTOOL/2.0-foss-2016b-rc7-CentOS6.8\n",
    "echo \"Module qctool loaded\"\n",
    "{cmd}\n",
    "'''\n",
    "parameter: plink2_module = '''\n",
    "module load PLINK/2_x86_64_20180428\n",
    "echo \"Module plink2 loaded\"\n",
    "{cmd}\n",
    "'''\n",
    "\n",
    "parameter: plink_module = '''\n",
    "module load PLINK/1.90-beta5.3\n",
    "echo \"Module plink loaded\"\n",
    "{cmd}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[utils]\n",
    "output: f'{cwd:a}/utils.py'\n",
    "report: expand = '${ }', output=_output\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    def read_sumstat(file, config_file):\n",
    "        sumstats = pd.read_csv(file, compression='gzip', header=0, sep='\\t', quotechar='\"')        \n",
    "        import yaml\n",
    "        config = yaml.safe_load(open(config_file, 'r'))\n",
    "        try:\n",
    "            sumstats = sumstats.loc[:,list(config.values())]\n",
    "        except:\n",
    "            raise ValueError(f'According to {config_file}, input summary statistics should have the following columns: {list(config.values())}.')\n",
    "        sumstats.columns = list(config.keys())\n",
    "        return sumstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[default_0]\n",
    "depends: Py_Module('pandas_plink'), Py_Module('pybgen')\n",
    "input: sumstats_path, output_from('utils')\n",
    "output: sumstats = f'{cwd}/{_input:bn}.sumstats.gz',\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '2h', mem = '12G', cores = 1, tags = f'{step_name}_{_output[0]:bn}'\n",
    "python: expand = '${ }', input = _input[4], stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout'\n",
    "    \n",
    "    # Load the file of summary statistics and standardize it.\n",
    "    sumstats = read_sumstat(${_input[0]:r}, ${format_config_path:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Select a subset of samples from the BGEN files\n",
    "[default_1]\n",
    "depends: f'{cwd}/{unrelated_samples:bn}.{ld_sample_size}.txt'\n",
    "input: bgenFile, group_by=1\n",
    "output: f'{cwd}/{_input:bn}.{ld_sample_size}.bgen', f'{cwd}/{_input:bn}.{ld_sample_size}.sample'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h',  mem = '12G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', template = '{cmd}' if executable('qctools').target_exists() else qctool_module\n",
    "    qctool \\\n",
    "    -g ${_input} \\\n",
    "    -s ${sampleFile} \\\n",
    "    -og ${_output[0]} \\\n",
    "    -os ${_output[1]} \\\n",
    "    -incl-samples ${_depends}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Make the binary files for the selected samples \n",
    "[default_2]\n",
    "output: f'{_input[0]:n}.bed'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '12G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', template = '{cmd}' if executable('plink2').target_exists() else plink2_module\n",
    "    plink2 \\\n",
    "    --bgen ${_input[0]} ref-first \\\n",
    "    --sample ${_input[1]} \\\n",
    "    --make-bed \\\n",
    "    --out ${_output:n} \\\n",
    "    --threads ${numThreads}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Remove multiallelic variants and rename indels \n",
    "[default_3]\n",
    "depends: Py_Module('xxhash')\n",
    "output: f'{cwd}/{_input[0]:bn}.filtered.bed'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '12G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', template = '{cmd}' if executable('plink').target_exists() else plink_module\n",
    "    cut  -d$'\\t' -f2 ${_input[0]:n}.bim | sort | uniq -d > ${_output:nn}.exclude\n",
    "    plink2 \\\n",
    "    --bfile ${_input[0]:n} \\\n",
    "    --exclude ${_output:nn}.exclude \\\n",
    "    --make-bed \\\n",
    "    --out ${_output:n} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory 12000\n",
    "    \n",
    "python: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    # Fix SNP names longer than 50 characters. \n",
    "    # This will result in a false insufficient memory alert and error in the next step, if not dealt with\n",
    "    import pandas as pd\n",
    "    from xxhash import xxh32 as xxh\n",
    "    def shorten_id(x):\n",
    "        return x if len(x) < 30 else f\"{x.split('_')[0]}_{xxh(x).hexdigest()}\"\n",
    "\n",
    "    dat = pd.read_csv('${_output:n}.bim', header=None, sep='\\t')\n",
    "    dat.columns = ['chrom', 'id', 'gd', 'pos', 'a1', 'a2']\n",
    "    dat['id'] = dat['id'].apply(shorten_id)\n",
    "    dat.to_csv('${_output:n}.bim', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Merge all the .bed files into one reference file \n",
    "[default_4]\n",
    "input: group_by = 'all'\n",
    "output: f'{cwd}/{bfile:bn}.ref_geno.bed'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '64G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', template = '{cmd}' if executable('plink').target_exists() else plink_module\n",
    "    echo -e ${' '.join([str(x)[:-4] for x in _input[1:]])} | sed 's/ /\\n/g' > ${_output:n}.merge_list\n",
    "    plink \\\n",
    "    --bfile ${_input[0]:n} \\\n",
    "    --merge-list ${_output:n}.merge_list \\\n",
    "    --make-bed \\\n",
    "    --out ${_output:n} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory 64000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Perform LD-clumping in PLINKv1.9\n",
    "[default_5]\n",
    "output: f'{_input:nn}.clumped', f'{_input:nn}.clumped_region'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '12G',cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', template = '{cmd}' if executable('plink').target_exists() else plink_module    \n",
    "    plink \\\n",
    "    --bfile ${_input:n} \\\n",
    "    --clump ${sumstatsFiles:,} \\\n",
    "    --clump-field ${clump_field} \\\n",
    "    --clump-p1 ${clump_p1} \\\n",
    "    --clump-p2 ${clump_p2} \\\n",
    "    --clump-r2 ${clump_r2} \\\n",
    "    --clump-kb ${clump_kb} \\\n",
    "    --clump-verbose \\\n",
    "    --clump-annotate ${clump_annotate} \\\n",
    "    --clump-allow-overlap \\\n",
    "    --out ${_output[0]:n} \\\n",
    "    --threads ${numThreads} \\\n",
    "    && touch ${_output[0]} # need to touch and create empty file because some chroms may not have anything significant to clump.\n",
    "    grep \"RANGE\" ${_output[0]} | awk -F \":\" '{print $2, $3}' | sort -V | sed 's/\\../ /g; s/^[[:blank:]]*//g' > ${_output[1]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.21.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
