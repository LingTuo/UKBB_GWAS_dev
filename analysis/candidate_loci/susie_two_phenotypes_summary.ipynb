{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# SuSiE RSS Overlap\n",
    "\n",
    "Using the intermediary finemapping results from the SuSiE RSS finemapping pipeline, the current pipeline determines if there is overlap between two or more phenotypes between regions of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "To run this notebook follow the example:\n",
    "\n",
    "```\n",
    "sos run SuSiE_RSS.ipynb \\\n",
    "    --cwd /gpfs/gibbs/pi/dewan/data/UKBiobank/results/fine_mapping/f3393_hearing_aid \\\n",
    "    --finemapped_region_dirs_file /gpfs/gibbs/pi/dewan/data/UKBiobank/results/region_extraction/f3393_hearing_aid \\\n",
    "    --region_file /gpfs/gibbs/pi/dewan/data/UKBiobank/results/region_extraction/f3393_hearing_aid/regions.txt \\\n",
    "    --sumstats_path /gpfs/gibbs/pi/dewan/data/UKBiobank/results/FastGWA_results/results_imputed_data/f3393_hearing_aid/*.snp_stats.gz \\\n",
    "    --container_lmm /home/dc2325/scratch60/lmm_v_1_4.sif \\\n",
    "    --container_marp /gpfs/gibbs/pi/dewan/data/UKBiobank/marp.sif -s build\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Path to region extraction files\n",
    "parameter: finemapped_region_dirs_file = path\n",
    "#The region file after LD clumping\n",
    "parameter: region_file = path\n",
    "# parameter: sumstats_file = path\n",
    "#The directory for output files\n",
    "parameter: cwd = path\n",
    "## The container with the lmm/marp software. Can be either a dockerhub image or a singularity `sif` file.\n",
    "parameter: container_lmm = 'statisticalgenetics/lmm:2.0'\n",
    "parameter: container_marp = 'gaow/marp'\n",
    "# Specific number of threads to use\n",
    "parameter: numThreads = 2\n",
    "\n",
    "fail_if(not region_file.is_file(), msg = 'Cannot find regions to fine map. Please specify them using ``--region-file`` option.')\n",
    "# Load all regions of interest. Each item in the list will be a region: (chr, start, end)\n",
    "regions = [x.strip() for x in open(region_file).readlines()]\n",
    "regions = [x.replace(' ', '_' ) for x in regions]\n",
    "\n",
    "fail_if(not finemapped_region_dirs_file.is_file(), msg = 'Cannot find directories of finemapped regions. Please specify them using ``--finemapped_region_dirs_file`` option.')\n",
    "finemapped_dirs = [x.strip() for x in open(finemapped_region_dirs_file).readlines()]\n",
    "finemapped_dirs = [x for x in finemapped_dirs]\n",
    "\n",
    "parameter: name = \"_\".join([ d.split(\"/\")[-1] for d in finemapped_dirs ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[default_1 (export utils script)]\n",
    "depends: Py_Module('os'), Py_Module('pandas'), Py_Module('numpy')\n",
    "output: f'{cwd:a}/utils.py'\n",
    "report: expand = '${ }', output=f'{cwd:a}/utils.py'\n",
    "\n",
    "# will load an rds file into python\n",
    "def load_rds(filename, types=None):\n",
    "    import os\n",
    "    import pandas as pd, numpy as np\n",
    "    import rpy2.robjects as RO\n",
    "    import rpy2.robjects.vectors as RV\n",
    "    import rpy2.rinterface as RI\n",
    "    from rpy2.robjects import numpy2ri\n",
    "    numpy2ri.activate()\n",
    "    from rpy2.robjects import pandas2ri\n",
    "    pandas2ri.activate()\n",
    "    def load(data, types, rpy2_version=3):\n",
    "        if types is not None and not isinstance(data, types):\n",
    "            return np.array([])\n",
    "        # FIXME: I'm not sure if I should keep two versions here\n",
    "        # rpy2_version 2.9.X is more tedious but it handles BoolVector better\n",
    "        # rpy2 version 3.0.1 converts bool to integer directly without dealing with\n",
    "        # NA properly. It gives something like (0,1,-234235).\n",
    "        # Possibly the best thing to do is to open an issue for it to the developers.\n",
    "        if rpy2_version == 2:\n",
    "            # below works for rpy2 version 2.9.X\n",
    "            if isinstance(data, RI.RNULLType):\n",
    "                res = None\n",
    "            elif isinstance(data, RV.BoolVector):\n",
    "                data = RO.r['as.integer'](data)\n",
    "                res = np.array(data, dtype=int)\n",
    "                # Handle c(NA, NA) situation\n",
    "                if np.sum(np.logical_and(res != 0, res != 1)):\n",
    "                    res = res.astype(float)\n",
    "                    res[res < 0] = np.nan\n",
    "                    res[res > 1] = np.nan\n",
    "            elif isinstance(data, RV.FactorVector):\n",
    "                data = RO.r['as.character'](data)\n",
    "                res = np.array(data, dtype=str)\n",
    "            elif isinstance(data, RV.IntVector):\n",
    "                res = np.array(data, dtype=int)\n",
    "            elif isinstance(data, RV.FloatVector):\n",
    "                res = np.array(data, dtype=float)\n",
    "            elif isinstance(data, RV.StrVector):\n",
    "                res = np.array(data, dtype=str)\n",
    "            elif isinstance(data, RV.DataFrame):\n",
    "                res = pd.DataFrame(data)\n",
    "            elif isinstance(data, RV.Matrix):\n",
    "                res = np.matrix(data)\n",
    "            elif isinstance(data, RV.Array):\n",
    "                res = np.array(data)\n",
    "            else:\n",
    "                # I do not know what to do for this\n",
    "                # But I do not want to throw an error either\n",
    "                res = str(data)\n",
    "        else:\n",
    "            if isinstance(data, RI.NULLType):\n",
    "                res = None\n",
    "            else:\n",
    "                res = data\n",
    "        if isinstance(res, np.ndarray) and res.shape == (1, ):\n",
    "            res = res[0]\n",
    "        return res\n",
    "    def load_dict(res, data, types):\n",
    "        '''load data to res'''\n",
    "        names = data.names if not isinstance(data.names, RI.NULLType) else [\n",
    "            i + 1 for i in range(len(data))\n",
    "        ]\n",
    "        for name, value in zip(names, list(data)):\n",
    "            if isinstance(value, RV.ListVector):\n",
    "                res[name] = {}\n",
    "                res[name] = load_dict(res[name], value, types)\n",
    "            else:\n",
    "                res[name] = load(value, types)\n",
    "        return res\n",
    "    #\n",
    "    if not os.path.isfile(filename):\n",
    "        raise IOError('Cannot find file ``{}``!'.format(filename))\n",
    "    rds = RO.r['readRDS'](filename)\n",
    "    if isinstance(rds, RV.ListVector):\n",
    "        res = load_dict({}, rds, types)\n",
    "    else:\n",
    "        res = load(rds, types)\n",
    "    return res\n",
    "\n",
    "\n",
    "# get a unique list of the input sequence\n",
    "def f7(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[default_2 (running multi pheno analysis)]\n",
    "depends: f'{cwd:a}/utils.py'\n",
    "output: overlap_analysis_summary = f'{cwd:a}/{name}.overlapped.md', variants_csv = f'{cwd}/{name}_overlapped_variants.csv'\n",
    "python: container=container_lmm, expand = \"${ }\"\n",
    "    theme = '''---\n",
    "    theme: base-theme\n",
    "    style: |\n",
    "     p {\n",
    "       font-size: 24px;\n",
    "       height: 900px;\n",
    "       margin-top:1cm;\n",
    "      }\n",
    "      img {\n",
    "        height: 70%;\n",
    "        display: block;\n",
    "        margin-left: auto;\n",
    "        margin-right: auto;\n",
    "      }\n",
    "      body {\n",
    "       margin-top: auto;\n",
    "       margin-bottom: auto;\n",
    "       font-family: verdana;\n",
    "      }\n",
    "    ---    \n",
    "    '''\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    import csv\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn\n",
    "\n",
    "    regions = ${regions}\n",
    "    finemapped_dirs = ${finemapped_dirs}\n",
    "\n",
    "    sep = '\\n\\n---\\n'\n",
    "\n",
    "    def fail_if(b, msg):\n",
    "        if b:\n",
    "            raise ValueError(msg)\n",
    "    \n",
    "    # will load an rds file into python\n",
    "    def load_rds(filename, types=None):\n",
    "        import os\n",
    "        import pandas as pd, numpy as np\n",
    "        import rpy2.robjects as RO\n",
    "        import rpy2.robjects.vectors as RV\n",
    "        import rpy2.rinterface as RI\n",
    "        from rpy2.robjects import numpy2ri\n",
    "        numpy2ri.activate()\n",
    "        from rpy2.robjects import pandas2ri\n",
    "        pandas2ri.activate()\n",
    "        def load(data, types, rpy2_version=3):\n",
    "            if types is not None and not isinstance(data, types):\n",
    "                return np.array([])\n",
    "            # FIXME: I'm not sure if I should keep two versions here\n",
    "            # rpy2_version 2.9.X is more tedious but it handles BoolVector better\n",
    "            # rpy2 version 3.0.1 converts bool to integer directly without dealing with\n",
    "            # NA properly. It gives something like (0,1,-234235).\n",
    "            # Possibly the best thing to do is to open an issue for it to the developers.\n",
    "            if rpy2_version == 2:\n",
    "                # below works for rpy2 version 2.9.X\n",
    "                if isinstance(data, RI.RNULLType):\n",
    "                    res = None\n",
    "                elif isinstance(data, RV.BoolVector):\n",
    "                    data = RO.r['as.integer'](data)\n",
    "                    res = np.array(data, dtype=int)\n",
    "                    # Handle c(NA, NA) situation\n",
    "                    if np.sum(np.logical_and(res != 0, res != 1)):\n",
    "                        res = res.astype(float)\n",
    "                        res[res < 0] = np.nan\n",
    "                        res[res > 1] = np.nan\n",
    "                elif isinstance(data, RV.FactorVector):\n",
    "                    data = RO.r['as.character'](data)\n",
    "                    res = np.array(data, dtype=str)\n",
    "                elif isinstance(data, RV.IntVector):\n",
    "                    res = np.array(data, dtype=int)\n",
    "                elif isinstance(data, RV.FloatVector):\n",
    "                    res = np.array(data, dtype=float)\n",
    "                elif isinstance(data, RV.StrVector):\n",
    "                    res = np.array(data, dtype=str)\n",
    "                elif isinstance(data, RV.DataFrame):\n",
    "                    res = pd.DataFrame(data)\n",
    "                elif isinstance(data, RV.Matrix):\n",
    "                    res = np.matrix(data)\n",
    "                elif isinstance(data, RV.Array):\n",
    "                    res = np.array(data)\n",
    "                else:\n",
    "                    # I do not know what to do for this\n",
    "                    # But I do not want to throw an error either\n",
    "                    res = str(data)\n",
    "            else:\n",
    "                if isinstance(data, RI.NULLType):\n",
    "                    res = None\n",
    "                else:\n",
    "                    res = data\n",
    "            if isinstance(res, np.ndarray) and res.shape == (1, ):\n",
    "                res = res[0]\n",
    "            return res\n",
    "        def load_dict(res, data, types):\n",
    "            '''load data to res'''\n",
    "            names = data.names if not isinstance(data.names, RI.NULLType) else [\n",
    "                i + 1 for i in range(len(data))\n",
    "            ]\n",
    "            for name, value in zip(names, list(data)):\n",
    "                if isinstance(value, RV.ListVector):\n",
    "                    res[name] = {}\n",
    "                    res[name] = load_dict(res[name], value, types)\n",
    "                else:\n",
    "                    res[name] = load(value, types)\n",
    "            return res\n",
    "        #\n",
    "        if not os.path.isfile(filename):\n",
    "            raise IOError('Cannot find file ``{}``!'.format(filename))\n",
    "        rds = RO.r['readRDS'](filename)\n",
    "        if isinstance(rds, RV.ListVector):\n",
    "            res = load_dict({}, rds, types)\n",
    "        else:\n",
    "            res = load(rds, types)\n",
    "        return res\n",
    "\n",
    "    # get a unique list of the input sequence\n",
    "    def f7(seq):\n",
    "        seen = set()\n",
    "        seen_add = seen.add\n",
    "        return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "    \n",
    "    # using this fxn we can find the overlap of any number of phenotypes\n",
    "    def find_overlap(regions, region_rds):\n",
    "        tot_overlap = []\n",
    "        for r in regions:\n",
    "            rds = region_rds[r]\n",
    "\n",
    "            overlap = dict()\n",
    "\n",
    "            # put all the variants in the first pheno into overlap\n",
    "            rd = rds[0]\n",
    "            if rd[\"sets\"][\"cs\"] == None:\n",
    "                print(f\"one phenotype has no CS\")\n",
    "                tot_overlap.append(dict())\n",
    "                continue\n",
    "\n",
    "            for cset in rd[\"sets\"][\"cs\"].keys():\n",
    "                if isinstance(rd[\"sets\"][\"cs\"][cset], np.ndarray):\n",
    "                    print(\"first rd array\")\n",
    "                    for snp_ind in rd[\"sets\"][\"cs\"][cset]:\n",
    "                        snp_ind = snp_ind.item() - 1\n",
    "                        overlap[rd[\"pos\"][snp_ind]] = [snp_ind]\n",
    "                else:\n",
    "                    snp_ind = rd[\"sets\"][\"cs\"][cset]\n",
    "                    snp_ind = snp_ind.item() - 1\n",
    "                    overlap[rd[\"pos\"][snp_ind]] = [snp_ind]\n",
    "\n",
    "            try:\n",
    "                for n, rd in enumerate(rds[1:]):\n",
    "                    if rd[\"sets\"][\"cs\"] == None:\n",
    "                        # we raise an error that will be caught when we know we have at least one pheno that doesn't\n",
    "                        # have any cs in this region, because we will find no overlaps here and should just move on\n",
    "                        # to the next region\n",
    "                        print(\"one phenotype has no CS\")\n",
    "                        raise ValueError(\"\") \n",
    "\n",
    "                    temp = dict()\n",
    "                    for cset in rd[\"sets\"][\"cs\"].keys():\n",
    "                        if isinstance(rd[\"sets\"][\"cs\"][cset], np.ndarray):\n",
    "                            for snp_ind in rd[\"sets\"][\"cs\"][cset]:\n",
    "                                snp_ind = snp_ind.item() - 1\n",
    "                                temp[rd[\"pos\"][snp_ind]] = snp_ind\n",
    "                        else:\n",
    "                            snp_ind = rd[\"sets\"][\"cs\"][cset]\n",
    "                            snp_ind = snp_ind.item() - 1\n",
    "                            temp[rd[\"pos\"][snp_ind]] = snp_ind\n",
    "\n",
    "                    # now we should have an ordered list of all the indicies wrt each phenotype for any snp that's overlapped\n",
    "                    org_overlap = list(overlap.keys())\n",
    "                    for o in org_overlap:\n",
    "                        if o not in temp.keys():\n",
    "                            del overlap[o]\n",
    "                        else:\n",
    "                            overlap[o].append(temp[o])\n",
    "            \n",
    "                if not overlap:\n",
    "                    # don't have any overlap so move on to the next region\n",
    "                    raise ValueError(\"\")\n",
    "                tot_overlap.append(overlap)\n",
    "\n",
    "            except:\n",
    "                print(f\"no overlap in region {r}\")\n",
    "                tot_overlap.append(dict())\n",
    "                continue\n",
    "\n",
    "\n",
    "        return tot_overlap\n",
    "\n",
    "    # return the total number of credible variants\n",
    "    def total_CVariants(rd):\n",
    "        tot = 0\n",
    "        if rd[\"sets\"][\"cs\"] == None:\n",
    "            return 0\n",
    "\n",
    "        for cset in rd[\"sets\"][\"cs\"].keys():\n",
    "            if isinstance(rd[\"sets\"][\"cs\"][cset], np.ndarray):\n",
    "                for snp_ind in rd[\"sets\"][\"cs\"][cset]:\n",
    "                    tot += 1\n",
    "            else:\n",
    "                tot += 1\n",
    "\n",
    "        return tot\n",
    "\n",
    "    for i in finemapped_dirs:\n",
    "        fail_if (not os.path.isdir(i), msg = f'{i} is not a directory')\n",
    "    \n",
    "    region_rds = dict()\n",
    "    for r in regions:\n",
    "        temp = []\n",
    "        for d in finemapped_dirs:\n",
    "            for i in os.listdir(d):\n",
    "                 if os.path.isfile(os.path.join(d,i)) and r in i and \".SuSiE_RSS.rds\" in i:\n",
    "                    temp.append(load_rds(os.path.join(d,i)))\n",
    "        fail_if(not len(temp) == len(finemapped_dirs), msg = f'region {r} has an error when obtaining rsd files')\n",
    "        fail_if(not len(temp) > 1, msg = 'Do not have at least two phenotypes to compare')\n",
    "        region_rds[r] = temp\n",
    "\n",
    "\n",
    "    with open(${_output[\"overlap_analysis_summary\"]:r}, \"w\") as f:\n",
    "        tot_overlap = find_overlap(regions, region_rds)\n",
    "\n",
    "        # first want to make a bar graph of the total number of credible variants in each phenotype for each region\n",
    "\n",
    "        # each region will be one group\n",
    "        # per group we'll have the number of variants per phenotype, and then the overlapped number\n",
    "\n",
    "        phenos = [ d.split(\"/\")[-1] for d in finemapped_dirs ]\n",
    "    \n",
    "        data = []\n",
    "        col = [\"Region\"]\n",
    "        col.extend([ \"full \" + p for p in phenos])\n",
    "        col.append(\"Overlap\")\n",
    "\n",
    "        for en, r in enumerate(regions):\n",
    "            temp = [r]\n",
    "\n",
    "            # for each phenotype collect the total number of \n",
    "            for rd in region_rds[r]:\n",
    "                temp.append(total_CVariants(rd))\n",
    "            temp.append(len(tot_overlap[en]))\n",
    "            data.append(temp)\n",
    "\n",
    "        df = pd.DataFrame(data, columns=col)\n",
    "\n",
    "        df.plot(x=\"Region\", kind='bar', stacked=False, figsize=(14,5))\n",
    "        plt.ylabel(\"Count of Credible Variants\")\n",
    "        plt.savefig(\"${cwd:a}/combo1.png\", bbox_inches='tight')\n",
    "    \n",
    "        text_temp = \"\"\n",
    "        text_temp += f\"#\\n\\n Numerical Summary of Overlap \\n\"\n",
    "        text_temp += f\"![](${cwd:a}/combo1.png){sep} \\n \\n\"\n",
    "        f.write(text_temp)\n",
    "\n",
    "        # this will be descriptive of the distribution\n",
    "        data = []\n",
    "        col = [\"Region\"]\n",
    "        col.extend([ \"only \" + p for p in phenos])\n",
    "        col.append(\"Overlap\")\n",
    "\n",
    "        for en, r in enumerate(regions):\n",
    "            total = 0\n",
    "            temp = []\n",
    "            # for each phenotype collect the total number of \n",
    "            for rd in region_rds[r]:\n",
    "                i = total_CVariants(rd) - len(tot_overlap[en])\n",
    "                total += i\n",
    "                temp.append(i)\n",
    "            i = len(tot_overlap[en])\n",
    "            total += i\n",
    "            temp.append(i)\n",
    "            temp = [t/total if total != 0 else 0 for t in temp]\n",
    "            temp.insert(0, r)\n",
    "            data.append(temp)\n",
    "\n",
    "        df = pd.DataFrame(data, columns=col)\n",
    "\n",
    "        df.plot(x=\"Region\", kind='bar', stacked=True, title='Numerical Summary of Overlap', figsize=(14,5))\n",
    "        plt.ylabel(\"Fraction of Credible Variants in Categories\")\n",
    "        plt.savefig(\"${cwd:a}/combo2.png\", bbox_inches='tight')\n",
    "    \n",
    "        text_temp = \"\"\n",
    "        text_temp += f\"#\\n\\n Numerical Summary of Overlap \\n\"\n",
    "        text_temp += f\"![](${cwd:a}/combo2.png){sep} \\n \\n\"\n",
    "        f.write(text_temp)\n",
    "\n",
    "\n",
    "        seaborn.set(style='ticks')\n",
    "        variant_info = []\n",
    "\n",
    "\n",
    "        for en, r in enumerate(regions):\n",
    "\n",
    "            overlap = tot_overlap[en]\n",
    "            if not overlap:\n",
    "                continue # because we have no overlap in this\n",
    "\n",
    "    \n",
    "            data = dict()\n",
    "            data[\"SNP\"] = []\n",
    "            data[\"PIP\"] = []\n",
    "            data[\"Pheno\"] = []\n",
    "\n",
    "            overlap = tot_overlap[en]\n",
    "            col = [\"SNP\", \"PIP\", \"Pheno\"]\n",
    "\n",
    "            for var in overlap.keys():\n",
    "                for pheno_ind, rd in enumerate(region_rds[r]):\n",
    "                    data[\"SNP\"].append(var)\n",
    "                    data[\"PIP\"].append(rd[\"pip\"][overlap[var][pheno_ind]])\n",
    "                    data[\"Pheno\"].append(phenos[pheno_ind])\n",
    "\n",
    "            df = pd.DataFrame(data, columns=col)\n",
    "            fg = seaborn.FacetGrid(data=df, hue='Pheno', hue_order=phenos, height=5, aspect=2.5)\n",
    "            fg.map(plt.scatter, \"SNP\", 'PIP').add_legend()\n",
    "            plt.title(\"Overlapped Variants for region \"+r)\n",
    "            plt.ticklabel_format(style='plain', axis='x')\n",
    "            plt.ylim(0,1)\n",
    "            plt.savefig(f\"${cwd:a}/{r}_scatter.png\", bbox_inches='tight')\n",
    "\n",
    "            text_temp = \"\"\n",
    "            text_temp += f\"#\\n\\n Finemapping Overlap {r} Scatter\\n\"\n",
    "            text_temp += f\"![](${cwd:a}/{r}_scatter.png){sep} \\n \\n\"\n",
    "            f.write(text_temp)\n",
    "\n",
    "            rds = region_rds[r]\n",
    "            rd = rds[0]\n",
    "            text_temp = \"\"\n",
    "            text_temp += f\"#\\n\\n Finemapping Overlap {r} \\n\"\n",
    "            text_temp += \"| chr number | pos | region id | \\n\"\n",
    "            text_temp += \"| --- | --- | --- | \\n\"\n",
    "\n",
    "            for snp in overlap.keys():\n",
    "                text_temp += f'| {rd[\"chr\"][0]} | {snp} | {r} | \\n'\n",
    "                i = overlap[snp][0] # index for the first pheno. w the assumption that all ref and alts are the same\n",
    "                temp = [rd[\"chr\"][i], rd[\"pos\"][i], rd[\"ref\"][i], rd[\"alt\"][i], r]\n",
    "                for en, phen_rd in enumerate(region_rds[r]):\n",
    "                    temp.append(phen_rd[\"pip\"][overlap[snp][en]])\n",
    "                variant_info.append(temp)\n",
    "        \n",
    "            text_temp += sep\n",
    "            f.write(text_temp)\n",
    "\n",
    "        col = [\"chr\", \"pos\", \"ref\", \"alt\", \"rid\"]\n",
    "        col.extend([f\"{p}_pip\" for p in phenos])\n",
    "        print(col)\n",
    "        df = pd.DataFrame(variant_info, columns=col)\n",
    "        print(df)\n",
    "        df.to_csv(${_output[\"variants_csv\"]:r}, sep = \",\", header = True, index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Generate analysis report: HTML file, and optionally PPTX file\n",
    "[default_3]\n",
    "output: f\"{_input['overlap_analysis_summary']:n}.html\"\n",
    "sh: container=container_marp, expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    node /opt/marp/.cli/marp-cli.js ${_input['overlap_analysis_summary']} -o ${_output:a} \\\n",
    "        --title '${region_file:bnn} overlap fine mapping analysis' \\\n",
    "        --allow-local-files\n",
    "    node /opt/marp/.cli/marp-cli.js ${_input['overlap_analysis_summary']} -o ${_output:an}.pptx \\\n",
    "        --title '${region_file:bnn} overal fine mapping analysis' \\\n",
    "        --allow-local-files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
