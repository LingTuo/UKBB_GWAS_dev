{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a329e2f4-d6cf-41b2-9a24-c4cf40b89c53",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Example on how to use of regenie for single variant analysis of exome data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e00a373-8cab-41f4-9d33-6d8d9270164e",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "[Regenie](https://rgcgithub.github.io/regenie/) is a program that performs genome-wide association analysis in very large datases such as the UK Biobank.\n",
    "\n",
    "## Properties\n",
    "\n",
    "1. Works with quantitative and binary traits (case-control), including those with unbalanced samples case-control ratio. Supports Firth logistic regression and SPA for binary traits.\n",
    "2. Uses linear mixed models (LMM) for quantitative traits and generalized LMM (GLMM) for binayr traits, allowing for the inclusion of related individuals. \n",
    "3. Offers the advantage of processing multiple phenotypes at the same time. However you should be aware that quantitave or binary traits need to be analyzed separately. Also, the proportion of missing data should be similar for all of the traits analyzed at once, since it can impact predictions. Authors of regenie recommend to analyze traits in groups that have similar missingness patterns with resonably low amount of missingness (<15%).\n",
    "4. It can handle different types of data (microarray, imputed, exome sequencing) and formats (PLINK:bed/bim/fam, PLINK2:pgen/pvar/psam and BGEN).\n",
    "5. It is desgined to handle a large number of samples ~500K. Regenie is not appropiate to analyze small samples\n",
    "6. Integrates covariates into the model.\n",
    "\n",
    "## Method\n",
    "\n",
    "Regenie works in two different steps that are independent from each other. \n",
    "\n",
    "### Step 1. \n",
    "\n",
    "The first step is where it fits the null regression model, for this regenie uses a subset of genetic markers that capture a good proportion of the phenotype variance that is attributable to genetic effects\n",
    "\n",
    "- Level 0: Ridge regression applied to block of SNPs to reduce dimensions\n",
    "- Level 1: Linear or logistic ridge regressions within cross validation scheme\n",
    "\n",
    "### Step 2.\n",
    "\n",
    "A larger set of genetic markers is used to test for association, using a linear or logistic regression, with the traits conditional upon the prediction from the regression model on step 1. This is done by using the Leave One Chromosome Out (LOCO) scheme to avoid proximal contamination. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a52e9f1-d2e1-4b39-8de0-729ab121f802",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Pre-requisites\n",
    "\n",
    "In order to run this workflow you will need to have installed [docker](https://docs.docker.com/get-docker/) in you local computer previously, and have created and account.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ab12b4-ba01-4f44-a2ec-4a4f1372f2cf",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Toy dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cfab26-62c2-4007-8a58-64e8932d60df",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "For this exercise we will use data from 1000G pubicly available database.The populations in the dataset are GBR=82, FIN=99 and TSI=104.\n",
    "\n",
    "Please note that this is only an example dataset for real life applications a much larger sample size is necessary. Also due to the use of different populations the use of principal components may be necessary to avoid increased type I error. \n",
    "\n",
    "```\n",
    "1000G.EUR.fam\n",
    "1000G.EUR.bim\n",
    "1000G.EUR.bed\n",
    "```\n",
    "\n",
    "## Phenotype file\n",
    "\n",
    "For the 1000G data there is not phenotype data available. Therefore we have create a  disease x phenotype by randomly assigning study subjects as cases and controls. Therefore the data is generated under the null of no association. \n",
    "\n",
    "## Genotype file \n",
    "\n",
    "For this example we are providing you with a genotype file that has been pruned and filtered using some quality control criteria. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54c2d2c-6860-42a7-a6a4-0150f876902b",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "## Runing the single variant association analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e53bfa4-9e4d-4e89-addd-357e333ab7b1",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "**1. Prepare the data**\n",
    "\n",
    "In this example, we are going to use a subset of genetic markers from the data to fit the null model of step 1. \n",
    "\n",
    "This process has been already integrated in the [LMM pipeline](https://github.com/cumc/bioworkflows/blob/master/GWAS/LMM.ipynb) under the `regenie_qc` step. It is recommended to use the data from the genotype array in this step, as it provides better estimates of the phenotype variance. \n",
    "\n",
    "Note: make sure you don't have any SNVs with a very low minor allele count (MAC) for the single variant analysis, otherwise regenie will give an error message. \n",
    "\n",
    "Let the parameters for the initial quality control be:\n",
    "\n",
    "- maf_filter=0.01, we will keep only variant with MAF >1%\n",
    "- geno_filter=0.1, we will remove variants with > 10% genotypes missing\n",
    "- mind_filter=0.1, we will remove individals with > 10% genotypes missing \n",
    "- hwe_filter=5e-08, we will remove variants exceding a p-value for HWE > 5E-08\n",
    "\n",
    "The output produced in this part consist of two files:\n",
    "\n",
    "`1000G.EUR.mini.qc_pass.id` and `1000G.EUR.mini.qc_pass.snplist`, these contain the list of individuals and variants to keep in the step 1 of regenie. \n",
    "\n",
    "In this MWE we keep n=32,254 variants and n=489 samples that pass our QC filters. \n",
    "\n",
    "\n",
    "**2. Fitting the null**\n",
    "\n",
    "In this step, we will use the genotype file (that has been pruned and filtered previously) and we will tell regenie which samples and variants to keep based on the results of our QC. \n",
    "\n",
    "- bfile=1000G.EUR.filtered.pruned.bed, we will use a subset of the genotyped genetic markers to calculate the predictions. This file has been pruned using a window size of 100, step of 10 and a r^2 of 0.04.\n",
    "- block_size=1000 this will tell the program in how many \"chunks\" to divide the genotype file to make predictions\n",
    "\n",
    "The output produced in this step correspond to: \n",
    "\n",
    "- A set of files (depending on the number of phenotypes analyzed) containing genomic predictions for each phenotype from Step 1 `1000G.EUR.pheno_x.regenie_1.loco`\n",
    "- A file called `1000G.EUR.pheno_x.regenie_pred.list` listing the locations of the prediction files\n",
    "\n",
    "**3. Association analysis**\n",
    "\n",
    "In this step, namely step 2 of regenie, it will perform the single variant association analysis with each of the phenotypes. \n",
    "\n",
    "Note: a convenient quality of REGENIE is that step 1 and 2 are decoupled meaning that you can use all of the traits used in step 1 or just a subset of them for the association analysis. Also, you can test the association using array, exomed or imputed variants. \n",
    "\n",
    "For this example, we will use our phenotype for disease x with the following parameters:\n",
    "\n",
    "- trait='bt' Here you define whether your trait is binary of quantitative.\n",
    "- covarCol=sex. In our particular case we will only use sex as covariate. However, if you have more than one covariate you can input them here separeted by comma\n",
    "- qCovarCol We will leave this variable empty in our analysis, but as above you can give a list of quantitative variables. \n",
    "- minMac=5 this flag is used to tell the program which minimum minor allele count (MAC) to use when testing variants, default value is 5. \n",
    "\n",
    "Depending on the type of data you are using, there are other useful parameters that you can explore. For example, with imputed data you may want to set the minimum info score to use (`--minINFO`), with quantitative phenotypes you may choose to use an inverse rank normalization (`--apply-rint`), for binary traits you can decide whether to use Firth (`--firth`) or Saddle Point Approximation (`--spa`) corrections.\n",
    "\n",
    "The output produced in this step corresponds to:\n",
    "\n",
    "- Summary statistics in a file with `*.regenie` extension, if option `-gz` was used this files will be compressed `*.regenie.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd790ef-2eef-4728-a4d4-7a4f7490d7e6",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "### REGENIE example command\n",
    "On a minimal working example (MWE) dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874e88e1-07bc-4308-b9c3-ea5e7619caa1",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Because step 1 (fitting the null) is the most time consuming in Regenie, it takes about ~15 minutes for this MWE (including the QC). We are proving in the output_burden folder the already generated files for this step. To start running from step 2 (the association analysis, that takes ~3 minutes) you only need to specify `-s build` in sos command line, so that those first steps are not run again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f47b8e-e425-48ef-9eb9-35f5256e3e3a",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# set working directory\n",
    "wd='regenie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcad6833-fef3-4e8e-8b9a-987338125167",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sos run regenie.ipynb regenie \\\n",
    "    --cwd $wd/output \\\n",
    "    --bfile $wd/data/1000G.EUR.filtered.pruned.bed \\\n",
    "    --maf-filter 0.01 \\\n",
    "    --geno-filter 0.1 \\\n",
    "    --mind-filter 0.1 \\\n",
    "    --hwe_filter 5e-08 \\\n",
    "    --genoFile $wd/data/1000G.EUR.filtered.pruned.bed \\\n",
    "    --phenoFile $wd/data/1000G.EUR.pheno.x \\\n",
    "    --formatFile $wd/data/regenie_template.yml\\\n",
    "    --phenoCol x\\\n",
    "    --covarCol sex \\\n",
    "    --qCovarCol \\\n",
    "    --numThreads 8 \\\n",
    "    --bsize 1000 \\\n",
    "    --trait bt \\\n",
    "    --minMAC 5 \\\n",
    "    --reverse_log_p \\\n",
    "    --p-filter 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7724f948-3119-4da6-a344-eac33c438545",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "#### Manhattan plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ea677-525a-4aa8-aac1-f90cf8f98d64",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "%preview -s png $wd/output/1000G.EUR.pheno_x.regenie.manhattan.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abebfc01-2f5a-41a8-b957-89f05bd9b563",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "#### Q-Q plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa1653-fb3f-4913-883d-45492e02acd8",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%preview -s png $wd/output/1000G.EUR.pheno_x.regenie.qq.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8612c062-4ed8-45e5-a0b7-6b9fe6d6e1a8",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Lambda GC value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d70ca2a-bfd8-4819-bbd6-7b9ce9f0f066",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat $wd/output/1000G.EUR.pheno_x.regenie.analysis_summary.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a11b3b-ba1d-4448-9312-4840517833e8",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Runing the burden test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ae4a29-01ab-4a77-8bd0-46ff81fb8358",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Regenie offers the functionality of performing rare-variant aggregate association analysis in the form of burden tests.  \n",
    "\n",
    "You can combine rare-variants in a gene or a region, using functional annotations to create masks that are then tested for association (as in a single variant analysis) with a phenotype. \n",
    "\n",
    "Input files:\n",
    "\n",
    "1. You will need to provide an annotation file that is formatted: variant_id, gene/region, functional annotation (e.g. LoF, missense). You can use VEP or ANNOVAR to generate this information and then format it accordingly. \n",
    "2. Provide the set-list-file: this file contains a list of variants within each gene/region that's used when building the masks. The format is: gene/region name, chromosome, start_position, list of variants in the gene/region separated by comma. \n",
    "3. Optional: provide a file with genes/regions that you want to include or exclude from your analysis.\n",
    "4. Optional: provide an allele-frequency file to use when creating the masks. By default the allele frequency is computed from the sample. In our case we are providing a allele-frequency file, obtained from gnomAD. In this case we used the AF_nfe field which contains the allele frequencies for non Finnish Europeans available in gnomAD. \n",
    "5. Mask file: this is a text file that contains the name of the mask and the type of annotations to use when building it (one mask per line). E.g. \n",
    "\n",
    "```\n",
    "mask1 LoF,missense\n",
    "```\n",
    "\n",
    "6. You need to provide the `--aaf-bins` cut-off in the parameters. This refers to the AAF upper bounds to use when creating the masks. By default regenie_burden produces results for singletons and if you set `--aaf-bins` to be for example 0.01 it will create masks from  [0,0.01] and singletons. \n",
    "\n",
    "Additionally, you can choose the way the mask are built among these options:\n",
    "- using the maximum number of ALT alleles across sites ('max'; the default)\n",
    "- using the sum of ALT alleles ('sum')\n",
    "- using a maximum threshold of 2 ('comphet')\n",
    "\n",
    "![Rules to build mask](https://rgcgithub.github.io/regenie/img/mask_rules.png)\n",
    "\n",
    "\n",
    "For this MWE we have already generated the annotation, the set list, the allele frequency and the mask files that are provided in the annotation folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3552f7e4-dbfa-4505-8a9b-fbcafbf5d65f",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### Regenie burden example command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c37a10-427e-4fe0-8eb4-45a9420c6189",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Because step 1 (fitting the null) is the most time consuming in Regenie, it takes about ~15 minutes for this MWE (including the QC). We are proving in the output_burden folder the already generated files for this step. To start running from step 2 (the association analysis, that takes ~3 minutes) you only need to specify `-s build` in sos command line, so that those first steps are not run again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76931676-2340-430d-ba7d-15881c16151a",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run regenie.ipynb regenie_burden \\\n",
    "    --cwd $wd/output_burden \\\n",
    "    --bfile $wd/data/1000G.EUR.filtered.pruned.bed \\\n",
    "    --maf-filter 0.01 \\\n",
    "    --geno-filter 0.1 \\\n",
    "    --mind-filter 0.1 \\\n",
    "    --hwe_filter 5e-08 \\\n",
    "    --genoFile $wd/data/1000G.EUR.filtered.pruned.bed \\\n",
    "    --phenoFile  $wd/data/1000G.EUR.pheno.x \\\n",
    "    --formatFile $wd/data/regenie_template.yml\\\n",
    "    --phenoCol x \\\n",
    "    --covarCol sex \\\n",
    "    --qCovarCol \\\n",
    "    --numThreads 8 \\\n",
    "    --bsize 1000 \\\n",
    "    --trait bt \\\n",
    "    --minMAC 1 \\\n",
    "    --reverse_log_p \\\n",
    "    --p-filter 1 \\\n",
    "    --anno_file $wd/data/*.anno_file\\\n",
    "    --aaf_file $wd/data/*.aff_file\\\n",
    "    --set_list $wd/data/*.set_list_file\\\n",
    "    --mask_file $wd/data/*.mask_file\\\n",
    "    --build_mask max\\\n",
    "    --aaf_bins  0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6270267b-a0ab-4af6-b4a6-59df9a58bbe0",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### Output files\n",
    "\n",
    "After running regenie burden you will find the following output files:\n",
    "\n",
    "* `1000G.EUR.pheno_x.regenie_burden.mask1.0.01.snp_stats.gz` This file contains the results only for mask1 and 0.01 bin\n",
    "* `1000G.EUR.pheno_x.regenie_burden.mask1.0.01.remove_sin.snp_stats.gz` In this file genes with only one rare variant have been removed (this is the one we are going use to make the manhattan plot)\n",
    "\n",
    "After running this analysis you will see a warning in step regenie_burden_6 about some missing files. These files correspond to the singleton analysis, which for this MWE won't be generated. To ignore these errors we are adding the `-e ignore` in the example command, so that the pipeline can complete successfully. \n",
    "\n",
    "You will also see that both manhatttan and qq plots have been generated for mask1 with the 0.01 bin combination. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7e1390-199a-41d6-a35d-95a57b2e8dcf",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### Manhattan plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8965625-621a-4bad-9d3f-1ca4e6062e4a",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "%preview -s png $wd/output_burden/1000G.EUR.pheno_x.regenie_burden.mask1.0.01.manhattan.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3913b1fe-1dd1-4dce-8838-ce803ce23056",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### Q-Q plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a406f1-4ca8-4232-ba2b-164b38ebfc35",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "%preview -s png $wd/output_burden/1000G.EUR.pheno_x.regenie_burden.mask1.0.01.qq.png"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "calysto_bash",
     "Bash",
     "#E6EEFF",
     "shell"
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
