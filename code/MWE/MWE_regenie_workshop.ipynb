{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a329e2f4-d6cf-41b2-9a24-c4cf40b89c53",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# GWAS: Regenie for single variant and burden analysis in a public data-set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0a5997-810d-477c-85ed-be3c4eff734f",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Here we show a how to run a genome wide association analysis (GWAS) using regenie with our `regenie.ipynb` pipeline using a public dataset from 1000 genomes. \n",
    "\n",
    "This tutorial has been created to be run on a single computer (a desktop, laptop, or a single interactive node on a cluster). The pipeline has been implemented in SoS workflow language and can be configured to run in parallel on a high performance computing cluster environment. Please read the [SoS documentation](https://vatlab.github.io/sos-docs/doc/user_guide/host_setup.html) on how to configure the software and workflow to efficiently perform the analysis for real-world data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e00a373-8cab-41f4-9d33-6d8d9270164e",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Over the past few years, there have been many tools created to run GWAS with increasing number of samples and genetic variants. Aditionally, these softwares use linear mixed models (LMM) to account for population structure, sample relatedness and estimate the genetic architecture of complex traits. BoltLMM, FastGWA and [Regenie](https://rgcgithub.github.io/regenie/) are some of them. \n",
    "\n",
    "Regenie can perform GWAS's in very large datases such as the UK Biobank.\n",
    "\n",
    "## Regenie properties\n",
    "\n",
    "1. Works with quantitative and binary traits (case-control), including those with unbalanced samples case-control ratio. Supports Firth logistic regression and SPA for binary traits.\n",
    "2. Uses linear mixed models (LMM) for quantitative traits and generalized LMM (GLMM) for binary traits, allowing for the inclusion of related individuals. \n",
    "3. Offers the advantage of processing multiple phenotypes at the same time. However you should be aware that quantitave or binary traits need to be analyzed separately. Also, the proportion of missing data should be similar for all of the traits analyzed at once, since it can impact predictions. Authors of regenie recommend to analyze traits in groups that have similar missingness patterns with resonably low amount of missingness (<15%).\n",
    "4. It can handle different types of data (microarray, imputed, exome sequencing) and formats (PLINK:bed/bim/fam, PLINK2:pgen/pvar/psam and BGEN).\n",
    "5. It is desgined to handle a large number of samples ~500K. Regenie is not appropiate to analyze small samples\n",
    "6. Integrates covariates into the model.\n",
    "\n",
    "## Method\n",
    "\n",
    "Regenie works in two different steps that are independent from each other. \n",
    "\n",
    "### Step 1. \n",
    "\n",
    "The first step is where it fits the null regression model, for this regenie uses a subset of genetic markers that capture a good proportion of the phenotype variance that is attributable to genetic effects\n",
    "\n",
    "- Level 0: Ridge regression applied to block of SNPs to reduce dimensions\n",
    "- Level 1: Linear or logistic ridge regressions within cross validation scheme\n",
    "\n",
    "### Step 2.\n",
    "\n",
    "A larger set of genetic markers is used to test for association, using a linear or logistic regression, with the traits conditional upon the prediction from the regression model on step 1. This is done by using the Leave One Chromosome Out (LOCO) scheme to avoid proximal contamination. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a52e9f1-d2e1-4b39-8de0-729ab121f802",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Pre-requisites\n",
    "\n",
    "In order to run this workflow you will need to have installed [docker](https://docs.docker.com/get-docker/) in you local computer previously, and have created an account.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ab12b4-ba01-4f44-a2ec-4a4f1372f2cf",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cfab26-62c2-4007-8a58-64e8932d60df",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Genotype data\n",
    "\n",
    "For this exercise we will use data from 1000 genomes pubicly available database downloaded from [MAGMA](https://ctg.cncr.nl/software/magma).The number of individuals in this data is n=489.\n",
    "\n",
    "Please note that this is only an example dataset for real life applications a much larger sample size is necessary. Also due to the use of different populations the use of principal components may be necessary to avoid increased type I error. \n",
    "\n",
    "```\n",
    "1000G.EUR.mwe.pruned.fam\n",
    "1000G.EUR.mwe.pruned.bim\n",
    "1000G.EUR.mwe.pruned.bed\n",
    "```\n",
    "\n",
    "The genotype file has been pruned in advance to make sure the excercise can be finished in a reasonable amount of time. For reproducibility these are the commands that have been used for pruning\n",
    "\n",
    "```\n",
    "plink2 --bfile 1000G.EUR --indep-pairwise 100 10 0.01 --out 1000G.EUR.mwe\n",
    "plink2 --bfile 1000G.EUR --extract 1000G.EUR.mwe.prune.in --make-bed --out 1000G.EUR.mwe.pruned\n",
    "```\n",
    "\n",
    "\n",
    "## Phenotype file\n",
    "\n",
    "For the 1000G data there is not phenotype data available. Therefore we have create a phenotype `x` by randomly assigning study subjects as cases and controls. Therefore the data is generated under the null of no association. \n",
    "\n",
    "```\n",
    "library(dplyr)\n",
    "EUR_subset_fam <- read.table('1000G.EUR.fam',  head=F)\n",
    "colnames(EUR_subset_fam) <- c(\"FID\", \"IID\", \"mother\", \"father\", \"sex\", \"phenotype\")\n",
    "EUR_subset_fam$x <- sample(c(0,1), replace=TRUE, size=489)\n",
    "EUR_subset_fam$sex <- sample(c(0,1), replace=TRUE, size=489)\n",
    "pheno <- EUR_subset_fam %>%\n",
    "    select('FID', \"IID\", \"sex\", \"x\")\n",
    "head(pheno)\n",
    "write.table(pheno,'1000G.EUR.pheno.x', sep=\"\\t\",row.names=F, quote=F)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a925cbe-c9bf-4f79-916d-f821f6f581d6",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[00m\n",
      "├── \u001b[01;34mdata\u001b[00m\n",
      "│   ├── 1000G.EUR.hg19.hg19_multianno.csv.aff_file\n",
      "│   ├── 1000G.EUR.hg19.hg19_multianno.csv.anno_file\n",
      "│   ├── 1000G.EUR.hg19.hg19_multianno.csv.set_list_file\n",
      "│   ├── 1000G.EUR.mask_file\n",
      "│   ├── 1000G.EUR.mwe.pruned.bed\n",
      "│   ├── 1000G.EUR.mwe.pruned.bim\n",
      "│   ├── 1000G.EUR.mwe.pruned.fam\n",
      "│   ├── 1000G.EUR.pheno.x\n",
      "│   └── regenie_template.yml\n",
      "├── regenie.ipynb\n",
      "└── regenie_example.ipynb\n",
      "\n",
      "1 directory, 11 files\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54c2d2c-6860-42a7-a6a4-0150f876902b",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "## 1. Runing the single variant association analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e53bfa4-9e4d-4e89-addd-357e333ab7b1",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "**1. Prepare the data**\n",
    "\n",
    "In this example, we are going to use a subset of genetic markers from the data to fit the null model of step 1. \n",
    "\n",
    "This process has been already integrated in the [LMM pipeline](https://github.com/cumc/bioworkflows/blob/master/GWAS/LMM.ipynb) under the `regenie_qc` step. It is recommended to use the data from the genotype array in this step, as it provides better estimates of the phenotype variance. \n",
    "\n",
    "Note: make sure you don't have any SNVs with a very low minor allele count (MAC) for the single variant analysis, otherwise regenie will give an error message. \n",
    "\n",
    "Let the parameters for the initial quality control be:\n",
    "\n",
    "- maf_filter=0.01, we will keep only variants with MAF >1%\n",
    "- geno_filter=0.1, we will remove variants with > 10% genotypes missing\n",
    "- mind_filter=0.1, we will remove individals with > 10% genotypes missing \n",
    "- hwe_filter=5e-08, we will remove variants exceding a p-value for HWE > 5E-08\n",
    "\n",
    "The output produced in this part consist of two files:\n",
    "\n",
    "`1000G.EUR.mwe.pruned.qc_pass.id` and `1000G.EUR.mwe.pruned.snplist`, these contain the list of individuals and variants to keep in the step 1 of regenie. \n",
    "\n",
    "In this MWE we keep n=102,497 variants and n=489 samples that pass our QC filters. \n",
    "\n",
    "\n",
    "**2. Fitting the null**\n",
    "\n",
    "In this step, we will use the genotype file and we will tell regenie which samples and variants to keep based on the results of our QC. \n",
    "\n",
    "- bfile=1000G.EUR.mwe.pruned, we will use a subset of the genotyped genetic markers to calculate the predictions.\n",
    "- block_size=1000 this will tell the program in how many \"chunks\" to divide the genotype file to make predictions\n",
    "\n",
    "The output produced in this step corresponds to: \n",
    "\n",
    "- A set of files (depending on the number of phenotypes analyzed) containing genomic predictions for each phenotype from Step 1 `1000G.EUR.pheno_x.regenie_1.loco`\n",
    "- A file called `1000G.EUR.pheno_x.regenie_pred.list` listing the locations of the prediction files\n",
    "\n",
    "**3. Association analysis**\n",
    "\n",
    "In this step, namely step 2 of regenie, it will perform the single variant association analysis with each of the phenotypes. \n",
    "\n",
    "Note: a convenient quality of REGENIE is that step 1 and 2 are decoupled meaning that you can use all of the traits used in step 1 or just a subset of them for the association analysis. Also, you can test the association using array, exomed or imputed variants. \n",
    "\n",
    "For this example, we will use our phenotype x with the following parameters:\n",
    "\n",
    "- trait='bt' Here you define whether your trait is binary of quantitative. \n",
    "- covarCol=sex. In our particular case we will only use sex as covariate. However, if you have more than one categorical covariate you can input them here separeted by comma\n",
    "- qCovarCol We will leave this variable empty in our analysis, but as above you can give a list of quantitative variables. \n",
    "- minMac=5 this flag is used to tell the program which minimum minor allele count (MAC) to use when testing variants, default value is 5. In real data applications you may want to set threshold depending on the power to detect associations based on your sample size. \n",
    "\n",
    "Depending on the type of data you are using, there are other useful parameters that you can explore. For example, with imputed data you may want to set the minimum info score to use (`--minINFO`), with quantitative phenotypes you may choose to use an inverse rank normalization (`--apply-rint`), for binary traits you can decide whether to use Firth (`--firth`) or Saddle Point Approximation (`--spa`) corrections.\n",
    "\n",
    "The output produced in this step corresponds to:\n",
    "\n",
    "- Summary statistics in a file with `*.regenie` extension, if option `-gz` was used this files will be compressed `*.regenie.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd790ef-2eef-4728-a4d4-7a4f7490d7e6",
   "metadata": {
    "kernel": "R"
   },
   "source": [
    "### REGENIE: single variant association analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874e88e1-07bc-4308-b9c3-ea5e7619caa1",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "We set the work directory to mwe_regenie folder (to be created by the workflow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f47b8e-e425-48ef-9eb9-35f5256e3e3a",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "wd=\"mwe_regenie\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b00c1f-7b73-4087-9c7d-032cad632593",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Now, we run the workflow `regenie` with the specific parameters. Please note that in this particular case, we are using the same file for calculating the predictions on Step 1 of regenie and for the association itself. However, for real life applications you may use different sets of files. For example genotype array data in bfile and exome sequencing data in the genoFile. \n",
    "\n",
    "Note: when you execute the cell using (shift + enter), a star will appear on the left side inside the box. When the star dissapears it means that the run has finished. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcad6833-fef3-4e8e-8b9a-987338125167",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sos run $wd/data/regenie.ipynb regenie \\\n",
    "    --cwd $wd/output \\\n",
    "    --bfile $wd/data/1000G.EUR.mwe.pruned.bed \\\n",
    "    --maf-filter 0.01 \\\n",
    "    --geno-filter 0.1 \\\n",
    "    --mind-filter 0.1 \\\n",
    "    --hwe_filter 5e-08 \\\n",
    "    --genoFile $wd/data/1000G.EUR.mwe.pruned.bed\\\n",
    "    --phenoFile $wd/data/1000G.EUR.pheno.x \\\n",
    "    --formatFile $wd/data/regenie_template.yml\\\n",
    "    --phenoCol x\\\n",
    "    --covarCol sex \\\n",
    "    --qCovarCol \\\n",
    "    --numThreads 8 \\\n",
    "    --bsize 1000 \\\n",
    "    --trait bt \\\n",
    "    --minMAC 5 \\\n",
    "    --reverse_log_p \\\n",
    "    --p-filter 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459d619d-7828-453b-b3a4-9c606f76781f",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Now let's visualize the results of the association"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7724f948-3119-4da6-a344-eac33c438545",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "#### Manhattan plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ea677-525a-4aa8-aac1-f90cf8f98d64",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "%preview -s png mwe_regenie/output/1000G.EUR.pheno_x.regenie.manhattan.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abebfc01-2f5a-41a8-b957-89f05bd9b563",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "#### Q-Q plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa1653-fb3f-4913-883d-45492e02acd8",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%preview -s png mwe_regenie/output/1000G.EUR.pheno_x.regenie.qq.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ff151f-2346-4126-b8ae-1a00e02127b7",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "**Question:** What is the inflation (lambda GC) value for this run? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8612c062-4ed8-45e5-a0b7-6b9fe6d6e1a8",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "#### Lambda GC value\n",
    "\n",
    "You can get a general idea of the number or cases/controls, the number of variants analyzed and the lambda GC values by taking a look at the markdown file generated in the `output` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d70ca2a-bfd8-4819-bbd6-7b9ce9f0f066",
   "metadata": {
    "kernel": "Bash",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat $wd/output/1000G.EUR.pheno_x.regenie.analysis_summary.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a11b3b-ba1d-4448-9312-4840517833e8",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## 2. Regenie : burden test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ae4a29-01ab-4a77-8bd0-46ff81fb8358",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Regenie offers the functionality of performing rare-variant aggregate association analysis in the form of burden tests.  \n",
    "\n",
    "You can combine rare-variants in a gene or a region, using functional annotations to create masks that are then tested for association (as in a single variant analysis) with a phenotype. \n",
    "\n",
    "### Input files:\n",
    "\n",
    "1. You will need to provide an `annotation file` that is formatted: variant_id, gene/region, functional annotation (e.g. LoF, missense). You can use VEP or ANNOVAR to generate this information and then format it accordingly. \n",
    "2. Provide the `set-list-file`: this file contains a list of variants within each gene/region that's used when building the masks. The format is: gene/region name, chromosome, start_position, list of variants in the gene/region separated by comma. \n",
    "3. Optional: provide a file with genes/regions that you want to include or exclude from your analysis.\n",
    "4. Optional: provide an `allele-frequency` file to use when creating the masks. By default the allele frequency is computed from the sample. In our case we are providing an allele-frequency file, obtained from gnomAD exome frequencies. We will use the AF_nfe field which contains the allele frequencies from exome data for non Finnish Europeans available in gnomAD. \n",
    "5. Mask file: this is a text file that contains the name of the mask and the type of annotations to use when building it (one mask per line). E.g. \n",
    "\n",
    "```\n",
    "mask1 LoF,missense\n",
    "```\n",
    "\n",
    "6. You need to provide the `--aaf-bins` cut-off in the parameters. This refers to the AAF upper bounds to use when creating the masks. By default regenie_burden produces results for singletons and if you set `--aaf-bins` to be for example 0.01 it will create masks from  [0,0.01] and singletons. \n",
    "\n",
    "Additionally, you can choose the way the mask are built among these options:\n",
    "- using the maximum number of ALT alleles across sites ('max'; the default)\n",
    "- using the sum of ALT alleles ('sum')\n",
    "- using a maximum threshold of 2 ('comphet')\n",
    "\n",
    "![Rules to build mask](https://rgcgithub.github.io/regenie/img/mask_rules.png)\n",
    "\n",
    "\n",
    "For this MWE we have already generated the annotation, the set list, the allele frequency and the mask files that are provided in the `data` folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3552f7e4-dbfa-4505-8a9b-fbcafbf5d65f",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### REGENIE: burden test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c37a10-427e-4fe0-8eb4-45a9420c6189",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Now, to run the burden test additional files need to be inputed such as the annotation, the set list , the mask and the allele frequency files described above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76931676-2340-430d-ba7d-15881c16151a",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run $wd/data/regenie.ipynb regenie_burden \\\n",
    "    --cwd $wd/output_burden \\\n",
    "    --bfile $wd/data/1000G.EUR.mwe.pruned.bed \\\n",
    "    --maf-filter 0.01 \\\n",
    "    --geno-filter 0.1 \\\n",
    "    --mind-filter 0.1 \\\n",
    "    --hwe_filter 5e-08 \\\n",
    "    --genoFile $wd/data/1000G.EUR.mwe.pruned.bed \\\n",
    "    --phenoFile  $wd/data/1000G.EUR.pheno.x \\\n",
    "    --formatFile $wd/data/regenie_template.yml\\\n",
    "    --phenoCol x \\\n",
    "    --covarCol sex \\\n",
    "    --qCovarCol \\\n",
    "    --numThreads 8 \\\n",
    "    --bsize 1000 \\\n",
    "    --trait bt \\\n",
    "    --minMAC 1 \\\n",
    "    --reverse_log_p \\\n",
    "    --p-filter 1 \\\n",
    "    --anno_file $wd/data/*.anno_file\\\n",
    "    --aaf_file $wd/data/*.aff_file\\\n",
    "    --set_list $wd/data/*.set_list_file\\\n",
    "    --mask_file $wd/data/*.mask_file\\\n",
    "    --build_mask max\\\n",
    "    --aaf_bins  0.01 -s build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6270267b-a0ab-4af6-b4a6-59df9a58bbe0",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### Output files\n",
    "\n",
    "After running regenie burden you will find the following output files in the `output_burden` folder:\n",
    "\n",
    "* `1000G.EUR.pheno_x.regenie_burden.mask1.0.01.snp_stats.gz` This file contains the results only for mask1 and 0.01 bin\n",
    "* `1000G.EUR.pheno_x.regenie_burden.mask1.0.01.manhattan.png` Manhattan pot\n",
    "* `1000G.EUR.pheno_x.regenie_burden.mask1.0.01.qq.png` Q-Q plot\n",
    "* `1000G.EUR.pheno_x.regenie_burden.mask1.0.01.analysis_summary.md` Markdown file with summarized information\n",
    "\n",
    "You can see that manhattan and qqplots have been generated for mask1 with the 0.01 bin combination. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7e1390-199a-41d6-a35d-95a57b2e8dcf",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### Manhattan plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8965625-621a-4bad-9d3f-1ca4e6062e4a",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "%preview -s png mwe_regenie/output_burden/1000G.EUR.pheno_x.regenie_burden.mask1.0.01.manhattan.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3913b1fe-1dd1-4dce-8838-ce803ce23056",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### Q-Q plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a406f1-4ca8-4232-ba2b-164b38ebfc35",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "%preview -s png mwe_regenie/output_burden/1000G.EUR.pheno_x.regenie_burden.mask1.0.01.qq.png"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "calysto_bash",
     "Bash",
     "#E6EEFF",
     "shell"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
