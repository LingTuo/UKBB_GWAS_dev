{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# PCA analysis UKBB data\n",
    "\n",
    "The intention of this notebook is to generate the PCA analysis and plots for the exomed samples 200K.\n",
    "\n",
    "Steps to generate a PCA include removing related individuals, pruning variants in linkage disequilibrium (LD), and excluding outlier samples that can suggest poor genotyping quality or distant relatedness (also restrict to individuals of homogeneous ancestry).\n",
    "\n",
    "Pitfalls\n",
    "1. Some of the PCs may capture LD structure rather than population structure (decrease in power to detect associations in these regions of high LD)\n",
    "2. When projecting a new study dataset to the PCA space computed from a reference dataset: projected PCs are shrunk toward 0 in the new dataset \n",
    "3.  PC scores may capture outliers that are due to family structure, population structure or other reasons; it might be beneficial to detect and remove these individuals to maximize the population structure captured by PCA (in the case of removing a few outliers) or to restrict analyses to genetically homogeneous samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## PCA analysis pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# the output directory for generated files\n",
    "parameter: cwd = path\n",
    "# BED Plink files for exome data\n",
    "parameter: bedfiles = paths\n",
    "# BIM Plink files for exome data\n",
    "parameter: bimfiles = paths\n",
    "# The fam file associated to the bed files\n",
    "parameter: famFile = path \n",
    "# The database to extract info from\n",
    "parameter: database = path\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Number of threads\n",
    "parameter: numThreads = 1\n",
    "# Load Plink module from cluster\n",
    "parameter: plink2_module = '''\n",
    "module load PLINK/2_x86_64_20180428\n",
    "echo \"Module PLINK2 loaded\"\n",
    "{cmd}\n",
    "'''\n",
    "parameter: plink_module = '''\n",
    "module load PLINK/1.90-beta5.3\n",
    "echo \"Module plink loaded\"\n",
    "{cmd}\n",
    "'''\n",
    "# Load Eigensoft module from cluster\n",
    "parameter: eigensoft_module = '''\n",
    "module load EIGENSOFT/7.2.1-foss-2018b\n",
    "echo \"Module Eigensoft v.7.2.1 loaded\"\n",
    "{cmd}\n",
    "'''\n",
    "# Software container option\n",
    "parameter: container_lmm = 'statisticalgenetics/lmm:1.4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Filter individuals from ancestries different than British, Irish, Other white background, prefer not to answer, do not know\n",
    "[filter_1: provides = [f'{cwd}/cache/{famFile:bn}.white_ind']]\n",
    "output: f'{cwd}/cache/{famFile:bn}.white_ind', f'{cwd}/cache/{famFile:bn}.white_ind.pheno'\n",
    "task: trunk_workers = 1, walltime = '10h', mem = '40G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: container=container_lmm, expand= \"${ }\", stderr = f'{_output[0]:nn}.stderr', stdout = f'{_output[0]:nn}.stdout'\n",
    "    #Load libraries\n",
    "    library('dplyr')\n",
    "    # This database is the one from June 2020 and contains a subset of variables with the PCs\n",
    "    fam <- read.table(${famFile:r}, sep=' ', header=F)\n",
    "    colnames(fam) <- c(\"FID\",\"IID\",\"fatherID\", \"motherID\", \"sex\", \"phenotype\")\n",
    "    cat(\"There are\",nrow(fam),\"individuals with exomes.\\n\")\n",
    "    bd <- read.table(${database:r}, sep=\"\\t\", header=T)\n",
    "    cat(\"The size of the full database is\",dim(bd),\".\\n\")\n",
    "    # Assign individual ID column to bd f.eid\n",
    "    names(bd)[1] <- \"IID\"\n",
    "    # Select the 200K individuals with exomes from the full db\n",
    "    exomed_IID <- bd[bd$IID %in% fam$IID,]\n",
    "    cat(\"The number of selected individuals is\",nrow(exomed_IID),\".\\n\")\n",
    "    # Filter db based on ethnicity variable\n",
    "    ethnicity <- exomed_IID %>%\n",
    "          select(IID, starts_with(\"f.21000\"))\n",
    "    # Function to extract all the available answers for 3 visits and put them in one list\n",
    "    f<-function(x){\n",
    "      visit<-c()\n",
    "      for (i in 2:4){\n",
    "        if (!is.na(x[i]))\n",
    "        {visit<-c(visit,x[i])}\n",
    "      }\n",
    "      if(is.null(visit)){visit=NA}\n",
    "      else{visit=as.numeric(visit)}\n",
    "      return (visit)\n",
    "    }\n",
    "\n",
    "    # Apply the above function and remove NAs\n",
    "    ethnicity$visit<-apply(ethnicity, 1, f)\n",
    "    # Filter out individuals wih missing values in ethnicity: 212 ind total\n",
    "    ethnicity <- ethnicity %>%\n",
    "      filter(!is.na(visit))\n",
    "    cat(\"There are\",nrow(ethnicity),\"individuals without missing values for ethnicity.\\n\")\n",
    "    # Identify the unique available codings in f.21000\n",
    "    code<-union(union(unique(ethnicity$f.21000.0.0),unique(ethnicity$f.21000.1.0)),unique(ethnicity$f.21000.2.0))\n",
    "    # Codes to keep white individuals\n",
    "    useful_code<-c(1001,1002,1003,1,-3,-1)\n",
    "    # the rest that donâ€™t have the combinations above can be set as NA\n",
    "    useless_code<-code[!code %in% useful_code] \n",
    "    useless_code<-useless_code[-which(is.na(useless_code))] # remove NA here in the vector\n",
    "    # Function to get the final code for ethnicity\n",
    "    f<-function(x){\n",
    "      l=length(unique(x$visit))\n",
    "      if (l==1){ # only one value available\n",
    "        result=unique(x$visit)\n",
    "      }\n",
    "      else{ # more then one value available\n",
    "        l=length(x$visit)\n",
    "        for (i in 1:l){\n",
    "          if (x$visit[i] %in% useless_code){result=NA; break} # inconsistent ones with conbination not wanted\n",
    "          else {result=9000} # inconsistent ones with right conbination\n",
    "        }\n",
    "      }\n",
    "      return(result)\n",
    "    }\n",
    "\n",
    "    # Apply the above function and remove NAs\n",
    "    ethnicity$new_ethnicity<-apply(ethnicity, 1, f)\n",
    "    # Filter by NA presence\n",
    "    ethnicity_noNA<-ethnicity %>%\n",
    "      filter(!is.na(new_ethnicity))\n",
    "    cat(\"There are\",nrow(ethnicity_noNA),\"individuals consistent for f.21000.\\n\")\n",
    "    ethnicity_isNA <- ethnicity %>%\n",
    "      filter(is.na(new_ethnicity))\n",
    "    cat(\"There are\",nrow(ethnicity_isNA),\"individuals inconsistent for f.21000.\\n\")\n",
    "    # keep only white individuals\n",
    "    white <- ethnicity_noNA %>%\n",
    "        filter(new_ethnicity %in% c(1,1001,1002,1003,-3,-1,9000)) %>%\n",
    "        mutate(FID = IID) %>%\n",
    "        select(FID,IID)\n",
    "    cat(\"After excluding non-white ethnic backgrounds, the number of white individuals is\",nrow(white),\".\\n\")\n",
    "    # Write the seleted individuals to a txt file\n",
    "    write.table(white,${_output[0]:r}, sep=\"\\t\", row.names=FALSE, col.names=F)\n",
    "    # Create the phenotype file\n",
    "    pheno <- ethnicity_noNA %>%\n",
    "        filter(new_ethnicity %in% c(1,1001,1002,1003,-3,-1,9000)) %>%\n",
    "        mutate(ethnicity = new_ethnicity) %>%\n",
    "        select(IID,ethnicity)\n",
    "    # Merge the two data frames\n",
    "    famfile <-merge(fam, pheno, by=\"IID\", all=FALSE)\n",
    "    cat(\"The famfile has \",nrow(famfile),\"individuals.\\n\")\n",
    "    write.table(famfile,${_output[1]:r}, sep=\"\\t\", row.names=FALSE, col.names=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Filter SNPs with MAF>1% for PCA analysis, select individuals and merge bed into one file\n",
    "[filter_2]\n",
    "parameter: maf_filter = 0.01\n",
    "#Maximum missingess per-variant\n",
    "parameter: geno_filter = 0.01\n",
    "#Maximum missingness per-sample\n",
    "parameter: mind_filter = 0.01\n",
    "parameter: hwe_filter = 0.0\n",
    "input: bedfiles, paired_with=['bimfiles'], group_by=1\n",
    "depends: f'{cwd}/cache/{famFile:bn}.white_ind'\n",
    "output: f'{cwd}/{_input:bn}.filtered.bed'\n",
    "task: trunk_workers = 1, walltime = '10h', mem = '30G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container_lmm, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', template = '{cmd}' if executable('plink2').target_exists() else plink2_module\n",
    "    plink2 \\\n",
    "      --bed ${_input}  --bim ${_input._bimfiles} --fam ${famFile} \\\n",
    "      ${('--maf %s' % maf_filter) if maf_filter > 0 else ''} ${('--geno %s' % geno_filter) if geno_filter > 0 else ''} ${('--hwe %s' % hwe_filter) if hwe_filter > 0 else ''} ${('--mind %s' % mind_filter) if mind_filter > 0 else ''} \\\n",
    "      --keep ${_depends} \\\n",
    "      --make-bed \\\n",
    "      --threads ${numThreads} \\\n",
    "      --out ${_output:n} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Merge all the .bed files into one bed file for input to eigensoft\n",
    "[filter_3]\n",
    "input: group_by = 'all'\n",
    "output: bfile_merge = f'{cwd}/{famFile:bn}.filtered.merged.bed'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '60G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', template = '{cmd}' if executable('plink').target_exists() else plink_module\n",
    "    echo -e ${' '.join([str(x)[:-4] for x in _input[1:]])} | sed 's/ /\\n/g' > ${_output:n}.merge_list\n",
    "    plink \\\n",
    "    --bfile ${_input[0]:n} \\\n",
    "    --merge-list ${_output:n}.merge_list \\\n",
    "    --make-bed \\\n",
    "    --out ${_output:n} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory 48000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# LD prunning window=50, shift-window every 5 SNPS, r2=0.5\n",
    "[filter_4]\n",
    "parameter: window = 50\n",
    "parameter: shift = 5\n",
    "parameter: r2 = 0.5\n",
    "output: f'{cwd}/{famFile:bn}.filtered.merged.prun.in'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '60G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', template = '{cmd}' if executable('plink').target_exists() else plink_module\n",
    "    plink \\\n",
    "    --bfile ${_input:n} \\\n",
    "    --indep-pairwise ${window} ${shift} ${r2}  \\\n",
    "    --out ${_output:nn} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory 48000\n",
    "    \n",
    "    plink \\\n",
    "    --bfile ${_input:n} \\\n",
    "    --extract ${_output} \\\n",
    "    --make-bed \\\n",
    "    --out ${_output:n} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run pca analysis using Eigenstrat: the program suports plink files here called PACKEDPED format\n",
    "# smartpca.perl: run PCA on input genotype data (calls smartpca)\n",
    "[pca_1]\n",
    "# Number of Principal Components to output\n",
    "parameter: k = int\n",
    "# Maximum number of iterations for outlier removal. Default 0 turns off outlier removal\n",
    "parameter: maxiter = 0\n",
    "# Number of principal components along which to remove outliers during each outlier removal iteration. Default is 10\n",
    "parameter: topk = 10\n",
    "# Number of standard deviations which an individual must exceed, along one of topk top principal components, in order to be removed as an outlier. Default is 6\n",
    "parameter: sigma = 6\n",
    "input: f'{cwd}/{famFile:bn}.filtered.merged.bed'\n",
    "output: f'{cwd}/{_input:bn}.pca'\n",
    "task: trunk_workers = 1, walltime = '10h', mem = '30G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout',  template = '{cmd}' if executable('smartpca.perl').target_exists() else eigensoft_module\n",
    "    #Create the parfile\n",
    "    genotypename: UKB_Caucasians_Subgroup_rs121Equal0_pruned.bed\n",
    "    snpname: UKB_Caucasians_Subgroup_rs121Equal0_pruned.bim\n",
    "    indivname: UKB_Caucasians_Subgroup_rs121Equal0_pruned.fam\n",
    "    outputformat: EIGENSTRAT\n",
    "    fastmode: YES\n",
    "    genotypeoutname: PCAoutput_UKB_Caucasians_Subgroup_rs121Equal0_pruned.geno\n",
    "    snpoutname: PCAoutput_UKB_Caucasians_Subgroup_rs121Equal0_pruned.snp\n",
    "    indivoutname: PCAoutput_UKB_Caucasians_Subgroup_rs121Equal0_pruned.ind\n",
    "    evecoutname: PCAoutput_UKB_Caucasians_Subgroup_rs121Equal0_pruned.evecout\n",
    "    evaloutname: PCAoutput_UKB_Caucasians_Subgroup_rs121Equal0_pruned.evalout\n",
    "    \n",
    "    \n",
    "    smartpca.perl \\\n",
    "    -i ${_input} \\ \n",
    "    -a ${_input:n}.bim \\\n",
    "    -b ${_input:n}.fam \\\n",
    "    -k ${k} \\\n",
    "    -o ${_output} \\\n",
    "    -p ${_output:n}.plot \\\n",
    "    -e ${_output:n}.eval \\\n",
    "    -l ${_output:n}.log \\\n",
    "    -m ${maxiter} \\\n",
    "    -t ${topk} \\\n",
    "    -s ${sigma}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[flashpca]\n",
    "# Number of Principal Components to output\n",
    "parameter: k = int\n",
    "# Maximum number of iterations for outlier removal. Default 0 turns off outlier removal\n",
    "parameter: maxiter = 0\n",
    "# Number of principal components along which to remove outliers during each outlier removal iteration. Default is 10\n",
    "parameter: topk = 10\n",
    "# Number of standard deviations which an individual must exceed, along one of topk top principal components, in order to be removed as an outlier. Default is 6\n",
    "parameter: sigma = 6\n",
    "input: f'{cwd}/{famFile:bn}.filtered.merged.bed'\n",
    "output: f'{cwd}/{_input:bn}.pca'\n",
    "task: trunk_workers = 1, walltime = '10h', mem = '30G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    fn <- ${_input:nr}\n",
    "    f <- flashpca(fn, ndim=10, stand=\"binom2\")\n",
    "    write.table(f$values,${_output:rn}.values, sep=\" \", row.names=FALSE, col.names=F) \n",
    "    write.table(f$vectors,${_output:rn}.vectors, sep=\" \", row.names=TRUE, col.names=F)\n",
    "    write.table(f$projection,${_output:rn}.projection, sep=\" \", row.names=TRUE, col.names=F)\n",
    "    write.table(f$loadings,${_output:rn}.loadings, sep=\" \", row.names=FALSE, col.names=F)\n",
    "    write.table(f$scale,${_output:rn}.scale, sep=\" \", row.names=FALSE, col.names=F)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.21.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
