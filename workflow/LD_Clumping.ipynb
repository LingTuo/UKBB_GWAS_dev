{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Identifying loci of interest from GWAS\n",
    "\n",
    "The aim is to select subsets of SNPs of possible interest (low p-value) from GWAS. We use LD clumping method to account for LD between SNPs. The output of LD clumping is a subset of independent SNPs for each locus of interest. We will use these SNPs to establish boundaries for these loci to be investigated further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input\n",
    "\n",
    "- Summary statistics\n",
    "- LD reference panel\n",
    "\n",
    "**Settings for clumping analysis:**\n",
    "\n",
    "1. Which reference dataset to use? Options are 1000G_CEU, hapmap_CEU_r23a_filtered, UK10K, HRC reference panel\n",
    "    \n",
    "    * FIXME: if the SNPs are not in the reference panel they won't be outputed as index SNPs\n",
    "    * FIX: use the bgen files with the genotype info for which we are going to extract 1000 individuals\n",
    "    \n",
    "    \n",
    "2. What is the significance threshold for the index variant (p1) we should use for the analyses? \n",
    "    \n",
    "    p=5e-08\n",
    "    \n",
    "3. What significance threshold to use for the SNPs to be clumped? \n",
    "   \n",
    "   p=1 (this will include all the SNPs)\n",
    "   \n",
    "4. What LD r2 to use? \n",
    "   \n",
    "   r2=0.3 or even lower to capture bigger LD blocks\n",
    "   \n",
    "5. What window size in kb to use (research about the average LD in the human genome for CEU population)? \n",
    "   \n",
    "   I decided to use 1Mb (1000Kb), however conversations with the team decided that 2Mb will be better\n",
    "\n",
    "Below are the default options used by PLINK\n",
    "\n",
    "```\n",
    "--clump-p1 0.0001: significance threshold for Index SNPs\n",
    "--clump-p2 0.01: Secondary significance threshold for clumped SNPs\n",
    "--clump-r2 0.50: LD threshold for clumping\n",
    "--clump-kb 250: Physical distance threshold for clumping\n",
    "--clump-field P_BOLT_LMM: To specify the name of the field for P-value\n",
    "--clump-verbose: to add a more detailed report of SNPs in each clump\n",
    "--clump-best: to select the single best proxy\n",
    "--clump-allow-overlap: allow for overlap between clumped regions\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Output\n",
    "\n",
    "A list of regions in the following format:\n",
    "\n",
    "```\n",
    "chr start end top_snp all_snps\n",
    "```\n",
    "\n",
    "where the last column `all_snps` are SNP IDs in the LD cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Command interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run LD_Clumping.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  filter_samples\n",
      "  default\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cwd VAL (as path, required)\n",
      "                        Working directory: change accordingly\n",
      "  --bfile VAL (as path, required)\n",
      "                        Genotype file in plink binary format\n",
      "  --bgenFile  paths\n",
      "\n",
      "                        Path to bgen files\n",
      "  --sampleFile VAL (as path, required)\n",
      "                        Path to sample files\n",
      "  --sumstatsFiles  paths\n",
      "\n",
      "                        Path to summary stats file\n",
      "  --unrelated-samples VAL (as path, required)\n",
      "                        Path to samples of unrelated individuals\n",
      "  --ld-sample-size 1000 (as int)\n",
      "                        Number of samples to use to compute LD\n",
      "  --clump-field VAL (as str, required)\n",
      "                        Clumping parameteres\n",
      "  --clump-annotate VAL (as str, required)\n",
      "  --clump-p1 5e-08 (as float)\n",
      "  --clump-p2 1 (as int)\n",
      "  --clump-r2 0.04 (as float)\n",
      "                        r2 = 0.04 => r = 0.2\n",
      "  --clump-kb 2000 (as int)\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --numThreads VAL (as int, required)\n",
      "                        Output the bgen file with 8bit formatting parameter:\n",
      "                        bgen_bits=16 Specific number of threads to use\n",
      "  --qctool-module '\\nmodule load QCTOOL/2.0-foss-2016b-rc7-CentOS6.8\\necho \"Module qctool loaded\"\\n{cmd}\\n'\n",
      "                        Load specific modules for each step\n",
      "  --plink2-module '\\nmodule load PLINK/2_x86_64_20180428\\necho \"Module plink2 loaded\"\\n{cmd}\\n'\n",
      "  --plink-module '\\nmodule load PLINK/1.90-beta5.3\\necho \"Module plink loaded\"\\n{cmd}\\n'\n",
      "\n",
      "Sections\n",
      "  filter_samples:       Create a white-space delimited file with a list of\n",
      "                        unrelated samples in data.\n",
      "  default_1:            Select a subset of samples from the BGEN files\n",
      "  default_2:            Make the binary files for the selected samples excluding\n",
      "                        repeated variant id FIXME the bim file would not exist\n",
      "                        at this point to create the .exclude file\n",
      "  default_3:            Merge all the .bed files into one reference file\n",
      "  default_4:            Perform LD-clumping in PLINKv1.9\n"
     ]
    }
   ],
   "source": [
    "sos run LD_Clumping.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Global parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Working directory: change accordingly\n",
    "parameter: cwd = path\n",
    "# Genotype file in plink binary format\n",
    "parameter: bfile = path\n",
    "# Path to bgen files\n",
    "parameter: bgenFile = paths\n",
    "# Path to sample files\n",
    "parameter: sampleFile = path\n",
    "# Path to summary stats file\n",
    "parameter: sumstatsFiles = paths\n",
    "# Path to samples of unrelated individuals\n",
    "parameter: unrelated_samples = path\n",
    "# Number of samples to use to compute LD\n",
    "parameter: ld_sample_size = 1000\n",
    "# Clumping parameteres\n",
    "parameter: clump_field = str\n",
    "parameter: clump_annotate = str\n",
    "parameter: clump_p1 = 5e-08\n",
    "parameter: clump_p2 = 1\n",
    "# r2 = 0.04 => r = 0.2\n",
    "parameter: clump_r2 = 0.04\n",
    "parameter: clump_kb = 2000\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Output the bgen file with 8bit formatting\n",
    "#parameter: bgen_bits=16\n",
    "# Specific number of threads to use\n",
    "parameter: numThreads = int\n",
    "# Load specific modules for each step\n",
    "parameter: qctool_module = '''\n",
    "module load QCTOOL/2.0-foss-2016b-rc7-CentOS6.8\n",
    "echo \"Module qctool loaded\"\n",
    "{cmd}\n",
    "'''\n",
    "parameter: plink2_module = '''\n",
    "module load PLINK/2_x86_64_20180428\n",
    "echo \"Module plink2 loaded\"\n",
    "{cmd}\n",
    "'''\n",
    "\n",
    "parameter: plink_module = '''\n",
    "module load PLINK/1.90-beta5.3\n",
    "echo \"Module plink loaded\"\n",
    "{cmd}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Illustration with a minimal working example\n",
    "\n",
    "\n",
    "```\n",
    "JOB_OPT='-j 2'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "On a minimal working example (MWE) dataset generated by the `LMM.ipynb` workflow,\n",
    "```\n",
    "sos run LD_Clumping.ipynb \\\n",
    "    --cwd output \\\n",
    "    --bfile data/genotypes.bed \\\n",
    "    --sampleFile data/imputed_genotypes.sample \\\n",
    "    --bgenFile data/imputed_genotypes_chr*.bgen \\\n",
    "    --sumstatsFile output/phenotypes_BMI.fastGWA.snp_stats.gz \\\n",
    "    --unrelated-samples data/unrelated_samples.txt \\\n",
    "    --numThreads 5 \\\n",
    "    --clump-p1 0.05 \\\n",
    "    --clump-field P \\\n",
    "    --clump-annotate BP \\\n",
    "    $JOB_OPT\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Note\n",
    "\n",
    "In step default_2 as per PLINK conditions duplicate variants have to be removed and indels renamed to >50 characters in lenght. PLINK1.9 is not capable of dealing with very long variant names and when merging different bed files it cannot handle multiallelic variants. The merge option is not available in PLINK2.0 as of this moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Select a random subset of unrelated samples\n",
    "\n",
    "The unrelated sample file should be a text file containing white space separated columns. It should have a column named `IID` for sample IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Create a white-space delimited file with a list of unrelated samples in data.\n",
    "[filter_samples: provides = f'{cwd}/{unrelated_samples:bn}.{ld_sample_size}.txt']\n",
    "input: unrelated_samples, sampleFile\n",
    "output: f'{cwd}/{unrelated_samples:bn}.{ld_sample_size}.txt'\n",
    "R: expand = \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    set.seed(1)\n",
    "    all_unrelated = read.table(${_input[0]:r}, header=T)\n",
    "    avail_samples = read.table(${_input[1]:r}, header=F, skip=2)\n",
    "    unrelated_samples = which(avail_samples[,1] %in% all_unrelated$IID)\n",
    "    dat = avail_samples[unrelated_samples,]\n",
    "    if (${ld_sample_size} < nrow(dat)) {\n",
    "      dat = dat[sample(1:nrow(dat), ${ld_sample_size}), 1, drop=F]\n",
    "    } else {\n",
    "      dat = dat[, 1, drop=F]\n",
    "    }\n",
    "    write.table(dat, ${_output:r}, quote=F, row.names=F, col.names=F)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Select Filter the BGEN files \n",
    "\n",
    "This step is based on the samples selected in the previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Select a subset of samples from the BGEN files\n",
    "[default_1]\n",
    "depends: f'{cwd}/{unrelated_samples:bn}.{ld_sample_size}.txt'\n",
    "input: bgenFile, group_by=1\n",
    "output: f'{cwd}/{_input:bn}.{ld_sample_size}.bgen', f'{cwd}/{_input:bn}.{ld_sample_size}.sample'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h',  mem = '60G', tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', template = '{cmd}' if executable('qctools').target_exists() else qctool_module\n",
    "    qctool \\\n",
    "    -g ${_input} \\\n",
    "    -s ${sampleFile} \\\n",
    "    -og ${_output[0]} \\\n",
    "    -os ${_output[1]} \\\n",
    "    -incl-samples ${_depends}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Make PLINK files with the selected samples\n",
    "\n",
    "The BGEN files extracted have to be converted to PLINK format because currently LD clumping in PLINK 1.9 does not work with BGEN format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Make the binary files for the selected samples excluding repeated variant id\n",
    "[default_2]\n",
    "depends: Py_Module('xxhash')\n",
    "output: f'{_input[0]:n}.bed'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '60G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', template = '{cmd}' if executable('plink2').target_exists() else plink2_module\n",
    "    # try create index if not exist\n",
    "    bgenix -g ${_input[0]} -index || true\n",
    "    # get a list of duplicated SNP IDs\n",
    "    bgenix -g ${_input[0]} -list 2>/dev/null | grep -v \"#\" | tail -n+2 | cut -d$'\\t' -f2 | sort | uniq -d > ${_output:n}.exclude\n",
    "    plink2 \\\n",
    "    --bgen ${_input[0]} ref-first \\\n",
    "    --sample ${_input[1]} \\\n",
    "    --make-bed \\\n",
    "    --exclude ${_output:n}.exclude \\\n",
    "    --out ${_output:n} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory 12000\n",
    "    \n",
    "python: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    # Fix SNP names longer than 50 characters. \n",
    "    # This will result in a false insufficient memory alert and error in the next step, if not dealt with\n",
    "    import pandas as pd\n",
    "    from xxhash import xxh32 as xxh\n",
    "    def shorten_id(x):\n",
    "        return x if len(x) < 30 else f\"{x.split('_')[0]}_{xxh(x).hexdigest()}\"\n",
    "\n",
    "    dat = pd.read_csv('${_output:n}.bim', header=None, sep='\\t')\n",
    "    dat.columns = ['chrom', 'id', 'gd', 'pos', 'a1', 'a2']\n",
    "    dat['id'] = dat['id'].apply(shorten_id)\n",
    "    dat.to_csv('${_output:n}.bim', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Merge all chroms to one file\n",
    "\n",
    "This is necessary for LD clumping in PLINK to work properly. We cannot merge bgen files to bed in PLINK 2 at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Merge all the .bed files into one reference file \n",
    "[default_3]\n",
    "input: group_by = 'all'\n",
    "output: f'{cwd}/' + \"_\".join([f'{x:bn}' for x in sumstatsFiles]) + '.ref_geno.bed'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '60G', cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', template = '{cmd}' if executable('plink').target_exists() else plink_module\n",
    "    echo -e ${' '.join([str(x)[:-4] for x in _input[1:]])} | sed 's/ /\\n/g' > ${_output:n}.merge_list\n",
    "    plink \\\n",
    "    --bfile ${_input[0]:n} \\\n",
    "    --merge-list ${_output:n}.merge_list \\\n",
    "    --make-bed \\\n",
    "    --out ${_output:n} \\\n",
    "    --threads ${numThreads} \\\n",
    "    --memory 48000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Perform LD clumping per chrom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Note: The same fields are extracted from all results files (e.g. SNP and P) -- i.e. it is not possible to specify different fields from different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Perform LD-clumping in PLINKv1.9\n",
    "[default_4]\n",
    "output: f'{_input:nn}.clumped', f'{_input:nn}.clumped_region'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = '48h', mem = '48G',cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "bash: expand= \"${ }\", stderr = f'{_output[0]:n}.stderr', stdout = f'{_output[0]:n}.stdout', template = '{cmd}' if executable('plink').target_exists() else plink_module    \n",
    "    plink \\\n",
    "    --bfile ${_input:n} \\\n",
    "    --clump ${sumstatsFiles:,} \\\n",
    "    --clump-field ${clump_field} \\\n",
    "    --clump-p1 ${clump_p1} \\\n",
    "    --clump-p2 ${clump_p2} \\\n",
    "    --clump-r2 ${clump_r2} \\\n",
    "    --clump-kb ${clump_kb} \\\n",
    "    --clump-verbose \\\n",
    "    --clump-annotate ${clump_annotate} \\\n",
    "    --clump-allow-overlap \\\n",
    "    --out ${_output[0]:n} \\\n",
    "    --threads ${numThreads} \\\n",
    "    && touch ${_output[0]} # need to touch and create empty file because some chroms may not have anything significant to clump.\n",
    "    grep \"RANGE\" ${_output[0]} | awk -F \":\" '{print $2, $3}' | sort -V | sed 's/\\../ /g; s/^[[:blank:]]*//g ; s/chr//g' > ${_output[1]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "Python3",
     "python3",
     "Python3",
     "#FFD91A",
     ""
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA",
     "r"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.21.7"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
